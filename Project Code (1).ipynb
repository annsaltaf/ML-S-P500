{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2299e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "hedge_fund = pd.read_csv('all_hedge_funds_balance_sheet.csv')  \n",
    "sp500 = pd.read_csv('HistoricalData_1731445986332.csv')        \n",
    "\n",
    "# Create a function to map quarterly dates to end-of-quarter dates\n",
    "def convert_quarter_to_date(quarter):\n",
    "    year, q = quarter.split(':')\n",
    "    quarter_end_mapping = {\n",
    "        'Q1': '-03-31',\n",
    "        'Q2': '-06-30',\n",
    "        'Q3': '-09-30',\n",
    "        'Q4': '-12-31'\n",
    "    }\n",
    "    return year + quarter_end_mapping[q]\n",
    "\n",
    "# Apply the conversion function to the hedge fund 'Date' column\n",
    "hedge_fund['Date'] = hedge_fund['Date'].apply(convert_quarter_to_date)\n",
    "hedge_fund['Date'] = pd.to_datetime(hedge_fund['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# Convert S&P500 Dates\n",
    "sp500['Date'] = pd.to_datetime(sp500['Date'], format='%m/%d/%Y')\n",
    "sp500['Quarter'] = sp500['Date'].dt.to_period('Q')\n",
    "\n",
    "# Aggregate S&P500 Data by Quarter\n",
    "sp500_quarterly = sp500.groupby('Quarter').agg({\n",
    "    'Close/Last': 'last'  \n",
    "}).reset_index()\n",
    "\n",
    "# Add Quarterly Period to Hedge Fund Data\n",
    "hedge_fund['Quarter'] = hedge_fund['Date'].dt.to_period('Q')\n",
    "\n",
    "# Merge Hedge Fund with S&P500 Quarterly Data\n",
    "merged_data = pd.merge(hedge_fund, sp500_quarterly, on='Quarter', how='inner')\n",
    "\n",
    "# Save the merged data to a new file\n",
    "merged_data.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the merged data\n",
    "print(merged_data.head())\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"merged_data.csv\")\n",
    "\n",
    "# ============================\n",
    "# Step 1: Data Preprocessing\n",
    "# ============================\n",
    "\n",
    "# Ensure 'Date' is in datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Create the target variable \n",
    "data['Next_Close'] = data['Close/Last'].shift(-1)\n",
    "data['Target'] = (data['Next_Close'] > data['Close/Last']).astype(int)\n",
    "data.drop(columns=['Next_Close'], inplace=True)\n",
    "\n",
    "# Feature Scaling \n",
    "scaler = StandardScaler()\n",
    "features = data.drop(columns=['Date', 'Quarter', 'Close/Last', 'Target'])\n",
    "X = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n",
    "y = data['Target']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ============================\n",
    "# Step 2: Define and Evaluate Models\n",
    "# ============================\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(name, y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "rf_metrics = evaluate_model(\"Random Forest\", y_test, y_pred_rf)\n",
    "\n",
    "# XGBoost\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, eval_metric='logloss', use_label_encoder=False)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "xgb_metrics = evaluate_model(\"XGBoost\", y_test, y_pred_xgb)\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg_all = LogisticRegression(max_iter=200)\n",
    "log_reg_all.fit(X_train, y_train)\n",
    "y_pred_logreg_all = log_reg_all.predict(X_test)\n",
    "log_reg_metrics = evaluate_model(\"Logistic Regression (All Data)\", y_test, y_pred_logreg_all)\n",
    "\n",
    "# LSTM\n",
    "\n",
    "# Reshape data for LSTM\n",
    "X_train_lstm = np.expand_dims(X_train.values, axis=1)\n",
    "X_test_lstm = np.expand_dims(X_test.values, axis=1)\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(64, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "lstm_model.add(Dropout(0.3))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=20, batch_size=32, validation_data=(X_test_lstm, y_test), callbacks=[early_stopping])\n",
    "\n",
    "y_pred_lstm = (lstm_model.predict(X_test_lstm) > 0.5).astype(int)\n",
    "lstm_metrics = evaluate_model(\"LSTM\", y_test, y_pred_lstm)\n",
    "\n",
    "# ARIMA\n",
    "arima_model = ARIMA(y_train, order=(1, 1, 1)).fit()\n",
    "y_pred_arima = (arima_model.forecast(steps=len(y_test)) > 0.5).astype(int)\n",
    "arima_metrics = evaluate_model(\"ARIMA\", y_test, y_pred_arima)\n",
    "\n",
    "# ============================\n",
    "# Step 3: Results Summary\n",
    "# ============================\n",
    "\n",
    "results = {\n",
    "    \"Random Forest\": rf_metrics,\n",
    "    \"XGBoost\": xgb_metrics,\n",
    "    \"Logistic Regression (All Data)\": log_reg_metrics,\n",
    "    \"LSTM\": lstm_metrics,\n",
    "    \"ARIMA\": arima_metrics\n",
    "}\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "for model, (acc, prec, rec, f1) in results.items():\n",
    "    print(f\"{model}:\")\n",
    "    print(f\" - Accuracy: {acc:.4f}\")\n",
    "    print(f\" - Precision: {prec:.4f}\")\n",
    "    print(f\" - Recall: {rec:.4f}\")\n",
    "    print(f\" - F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b21027c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
